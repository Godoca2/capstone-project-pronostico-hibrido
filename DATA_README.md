# GuÃ­a de Datos del Proyecto

## Archivos de Datos No Incluidos en el Repositorio

Por limitaciones de tamaÃ±o de GitHub (lÃ­mite 100MB por archivo), los siguientes archivos de datos **NO estÃ¡n incluidos** en este repositorio pero son necesarios para ejecutar los notebooks:

### Datos Requeridos

#### 1. **ERA5 Precipitation Data**
- **Archivo:** `data/processed/era5_precipitation_chile_full.nc`
- **TamaÃ±o:** ~45 MB
- **DescripciÃ³n:** PrecipitaciÃ³n diaria ERA5 para Chile Continental (2020)
- **Cobertura:** 17Â°S-56Â°S, 67Â°W-75Â°W, resoluciÃ³n 0.25Â°
- **CÃ³mo obtener:**
  ```bash
  # Ejecutar notebook de descarga
  python src/utils/download_era5.py --year 2020 --variable total_precipitation
  ```
  O descargar manualmente desde:
  - **ERA5 Land Hourly:** https://cds.climate.copernicus.eu/
  - Registrarse en CDS API
  - Usar script `src/utils/download_era5.py`

#### 2. **CHIRPS Satellite Data** (ValidaciÃ³n)
- **Archivo:** `data/external/chirps/chirps-v2.0.2019.days_p05.nc`
- **TamaÃ±o:** ~366 MB
- **DescripciÃ³n:** Datos satelitales CHIRPS para validaciÃ³n cruzada
- **ResoluciÃ³n:** 0.05Â° (~5.5 km)
- **CÃ³mo obtener:**
  ```bash
  # Descarga desde servidor CHIRPS
  wget ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/netcdf/p05/chirps-v2.0.2019.days_p05.nc -P data/external/chirps/
  ```
  O desde: https://www.chc.ucsb.edu/data/chirps

#### 3. **Kriging Interpolation Output**
- **Archivo:** `data/processed/kriging_precipitation_june_2020.nc`
- **TamaÃ±o:** ~60 MB
- **DescripciÃ³n:** Resultado de interpolaciÃ³n kriging (generado por Notebook 02)
- **CÃ³mo generar:**
  ```bash
  # Ejecutar Notebook 02
  jupyter notebook notebooks/02_Geoestadistica_Variogramas_Kriging.ipynb
  ```
  Este archivo se genera automÃ¡ticamente al ejecutar todas las celdas.

#### 4. **Modelos Entrenados** (Disponibles en repositorio)
- **Archivos:** 
  - `data/models/autoencoder_geostat.h5` (~4 MB) - AE+DMD baseline
  - `data/models/encoder_geostat.h5` (~2 MB) - Encoder standalone
  - `data/models/kovae_trained/kovae_full.h5` (~42 MB) - KoVAE completo
  - `data/models/kovae_trained/encoder.h5` - Encoder probabilÃ­stico
  - `data/models/kovae_trained/decoder.h5` - Decoder generativo
  - `data/models/kovae_trained/koopman_matrix.npy` - Matriz K 64Ã—64
  - `data/models/kovae_trained/config.pkl` - ConfiguraciÃ³n
  - `data/models/training_metrics.csv` - MÃ©tricas de entrenamiento
- **DescripciÃ³n:** Pesos entrenados de modelos (pipeline completo ejecutado)
- **MÃ©tricas validadas:**
  - AE+DMD: MAE=1.763 mm/dÃ­a, mejora +7.1% vs Persistence
  - KoVAE: MAE reconstrucciÃ³n=0.0029 mm/dÃ­a
- **CÃ³mo regenerar:**
  ```bash
  # Entrenar modelos desde cero
  jupyter notebook notebooks/03_AE_DMD_Training.ipynb  # AE+DMD
  jupyter notebook notebooks/05_KoVAE_Test.ipynb       # KoVAE
  ```

---

## Setup RÃ¡pido (ReproducciÃ³n Completa)

### OpciÃ³n 1: Desde Cero (Recomendado para Reproducibilidad)

```bash
# 1. Clonar repositorio
git clone https://github.com/Godoca2/Pronostico-Hibrido-Espacio-Temporal-de-Precipitaciones-en-Chile.git
cd Pronostico-Hibrido-Espacio-Temporal-de-Precipitaciones-en-Chile

# 2. Crear ambiente conda
conda env create -f conda.yaml
conda activate capstone

# 3. Instalar dependencias adicionales
pip install -r requirements.txt

# 4. Descargar datos ERA5
python src/utils/download_era5.py --year 2020 --variable total_precipitation --region chile

# 5. (Opcional) Descargar CHIRPS para validaciÃ³n
wget ftp://ftp.chg.ucsb.edu/pub/org/chg/products/CHIRPS-2.0/global_daily/netcdf/p05/chirps-v2.0.2019.days_p05.nc -P data/external/chirps/

# 6. Ejecutar pipeline completo
jupyter notebook notebooks/
# Ejecutar en orden: 01 â†’ 02 â†’ 03 â†’ 04 â†’ ... â†’ 08
```

### OpciÃ³n 2: Con Datos Pre-procesados (MÃ¡s RÃ¡pido)

Si tienes acceso a los datos ya descargados (por ejemplo, compartidos por Google Drive):

```bash
# 1. Clonar repositorio
git clone https://github.com/Godoca2/Pronostico-Hibrido-Espacio-Temporal-de-Precipitaciones-en-Chile.git
cd Pronostico-Hibrido-Espacio-Temporal-de-Precipitaciones-en-Chile

# 2. Descargar datos desde Google Drive/OneDrive/etc
# (Link provisto por el autor del proyecto)
# Descomprimir en las carpetas correspondientes:
unzip data_capstone.zip -d data/

# 3. Crear ambiente y ejecutar
conda env create -f conda.yaml
conda activate capstone
jupyter notebook notebooks/
```

---

## Descarga de Datos Pre-procesados

**Para revisores del proyecto (Profesor GuÃ­a, ComisiÃ³n Evaluadora):**

Los datos completos estÃ¡n disponibles en:
- **Google Drive:** [LINK_A_COMPARTIR]
- **OneDrive UDD:** [LINK_A_COMPARTIR]
- **TamaÃ±o total:** ~500 MB (comprimido)

Contenido del archivo `data_capstone.zip`:
```
data/
â”œâ”€â”€ external/
â”‚   â””â”€â”€ chirps/
â”‚       â””â”€â”€ chirps-v2.0.2019.days_p05.nc (366 MB)
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ era5_precipitation_chile_full.nc (45 MB)
â”‚   â””â”€â”€ kriging_precipitation_june_2020.nc (60 MB)
â””â”€â”€ models/
    â”œâ”€â”€ autoencoder_geostat.h5 (4 MB)
    â”œâ”€â”€ encoder_geostat.h5 (2 MB)
    â””â”€â”€ kovae_trained/
        â””â”€â”€ kovae_full.h5 (65 MB)
```

---

## VerificaciÃ³n de Datos

Para verificar que todos los datos necesarios estÃ¡n presentes:

```python
import os
from pathlib import Path

# Lista de archivos requeridos
required_files = [
    "data/processed/era5_precipitation_chile_full.nc",
    "data/external/chirps/chirps-v2.0.2019.days_p05.nc",
    "data/processed/kriging_precipitation_june_2020.nc",  # Generado por Notebook 02
]

# Verificar existencia
for file_path in required_files:
    if Path(file_path).exists():
        size_mb = Path(file_path).stat().st_size / (1024 * 1024)
        print(f"âœ… {file_path} ({size_mb:.2f} MB)")
    else:
        print(f"âŒ {file_path} - NO ENCONTRADO")
```

---

## Estructura de Datos Esperada

```
CAPSTONE_PROJECT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/
â”‚   â”‚   â””â”€â”€ chirps/
â”‚   â”‚       â””â”€â”€ *.nc (datos satelitales)
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ era5_precipitation_chile_full.nc
â”‚   â”‚   â”œâ”€â”€ kriging_precipitation_june_2020.nc
â”‚   â”‚   â”œâ”€â”€ metrics_summary.csv
â”‚   â”‚   â””â”€â”€ kovae_worst_cells_examples.csv
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ autoencoder_geostat.h5 (AE+DMD baseline)
â”‚   â”‚   â”œâ”€â”€ encoder_geostat.h5
â”‚   â”‚   â”œâ”€â”€ training_metrics.csv
â”‚   â”‚   â”œâ”€â”€ kovae_trained/
â”‚   â”‚   â”‚   â”œâ”€â”€ kovae_full.h5
â”‚   â”‚   â”‚   â”œâ”€â”€ encoder.h5
â”‚   â”‚   â”‚   â”œâ”€â”€ decoder.h5
â”‚   â”‚   â”‚   â”œâ”€â”€ koopman_matrix.npy
â”‚   â”‚   â”‚   â””â”€â”€ config.pkl
â”‚   â”‚   â”œâ”€â”€ ablation/
â”‚   â”‚   â””â”€â”€ ablation_long/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ precipitation_data.npy
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_Spatiotemporal.ipynb
â”‚   â”œâ”€â”€ 02_Geoestadistica_Variogramas_Kriging.ipynb
â”‚   â”œâ”€â”€ 03_AE_DMD_Training.ipynb
â”‚   â”œâ”€â”€ 04_Advanced_Metrics.ipynb
â”‚   â”œâ”€â”€ 05_KoVAE_Test.ipynb
â”‚   â”œâ”€â”€ 06_Hyperparameter_Experiments.ipynb
â”‚   â”œâ”€â”€ 07_DMD_Interpretability.ipynb
â”‚   â””â”€â”€ 08_CHIRPS_Validation.ipynb
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/ (65+ figuras generadas)
â”‚   â”œâ”€â”€ chirps_validation_summary.md
â”‚   â”œâ”€â”€ ablation_report.md
â”‚   â””â”€â”€ metrics_eval.csv
â””â”€â”€ src/
    â””â”€â”€ utils/
        â”œâ”€â”€ download_era5.py
        â”œâ”€â”€ download_chirps.py
        â””â”€â”€ metrics.py
```

---

## Requisitos del Sistema

### MÃ­nimos
- **Python:** 3.9+
- **RAM:** 16 GB
- **Almacenamiento:** 2 GB libres
- **GPU:** Opcional (CPU funciona pero mÃ¡s lento)

### Recomendados (para entrenamiento)
- **Python:** 3.10
- **RAM:** 32 GB
- **GPU:** NVIDIA con 8+ GB VRAM (CUDA 11.2+)
- **Almacenamiento:** 5 GB libres

---

## Troubleshooting

### Error: "FileNotFoundError: era5_precipitation_chile_full.nc"
**SoluciÃ³n:** Descargar datos ERA5 siguiendo instrucciones arriba.

### Error: "MemoryError durante carga de datos"
**SoluciÃ³n:** 
- Cerrar otras aplicaciones
- Usar chunks en xarray: `ds = xr.open_dataset(file, chunks={'time': 50})`

### Error: "ModuleNotFoundError: No module named 'pydmd'"
**SoluciÃ³n:** 
```bash
conda activate capstone
pip install pydmd
```

---

## Contacto

**Autor:** CÃ©sar Godoy Delaigue  
**InstituciÃ³n:** Universidad del Desarrollo (UDD)  
**Proyecto:** PronÃ³stico HÃ­brido Espacio-Temporal de Precipitaciones en Chile  
**Email:** [cesar.godoy@udd.cl]

Para acceso a datos pre-procesados o consultas sobre reproducciÃ³n, contactar al autor.

---

## ğŸ“„ Licencia

Los datos ERA5 y CHIRPS estÃ¡n sujetos a sus respectivas licencias:
- **ERA5:** Copernicus Climate Change Service (C3S)
- **CHIRPS:** UC Santa Barbara Climate Hazards Group

El cÃ³digo de este proyecto estÃ¡ bajo licencia MIT (ver LICENSE).
