# ğŸ“š GLOSARIO TÃ‰CNICO Y CIENTÃFICO
## Proyecto: PronÃ³stico HÃ­brido Espacio-Temporal de Precipitaciones en Chile

**VersiÃ³n:** 1.0  
**Fecha:** 23 de Noviembre de 2025  
**Autor:** CÃ©sar Godoy Delaigue

---

## ğŸ”¤ ÃNDICE ALFABÃ‰TICO

[A](#a) | [B](#b) | [C](#c) | [D](#d) | [E](#e) | [F](#f) | [G](#g) | [H](#h) | [I](#i) | [K](#k) | [L](#l) | [M](#m) | [N](#n) | [O](#o) | [P](#p) | [R](#r) | [S](#s) | [T](#t) | [U](#u) | [V](#v) | [W](#w)

---

## A

### ActivaciÃ³n (FunciÃ³n de)
FunciÃ³n matemÃ¡tica aplicada a la salida de una neurona en una red neuronal que introduce no linealidad. Las mÃ¡s comunes son ReLU, sigmoid, tanh y linear.

**Ejemplo en el proyecto:**
```python
layers.Conv2D(64, 3, activation='relu')
```

### AE (Autoencoder)
Red neuronal diseÃ±ada para aprender representaciones comprimidas (embeddings) de datos. Consta de un encoder (compresor) y un decoder (reconstructor).

**AplicaciÃ³n:** CompresiÃ³n espacial de campos de precipitaciÃ³n de 6437 â†’ 64 dimensiones.

### AgregaciÃ³n Temporal
Proceso de combinar datos de alta frecuencia temporal en intervalos mÃ¡s largos (ej: datos horarios â†’ diarios mediante suma o promedio).

**Ejemplo:** ERA5 horario (8784 horas/aÃ±o) â†’ ERA5 diario (366 dÃ­as/aÃ±o).

### AnisotropÃ­a
Propiedad de un campo espacial donde la correlaciÃ³n depende de la direcciÃ³n. Opuesto a isotropÃ­a.

**En precipitaciones:** CorrelaciÃ³n mayor en direcciÃ³n norte-sur que este-oeste debido a topografÃ­a andina.

---

## B

### Baseline (Modelo)
Modelo simple de referencia usado para comparaciÃ³n. Debe superarse para demostrar utilidad de modelos complejos.

**Baselines del proyecto:**
- **Persistence:** PronÃ³stico = Ãºltimo valor observado
- **ClimatologÃ­a:** PronÃ³stico = promedio histÃ³rico

### Batch Normalization
TÃ©cnica de normalizaciÃ³n de activaciones entre capas de una red neuronal que estabiliza y acelera el entrenamiento.

**FÃ³rmula:**
```
BN(x) = Î³ * (x - Î¼) / âˆš(ÏƒÂ² + Îµ) + Î²
```

### Batch Size
NÃºmero de muestras procesadas simultÃ¡neamente en una iteraciÃ³n de entrenamiento de red neuronal.

**Valor usado:** 16 muestras por batch.

---

## C

### Campo Aleatorio (Random Field)
Variable que toma valores en cada punto del espacio de forma estocÃ¡stica. Las precipitaciones son un campo aleatorio espacio-temporal.

### CHIRPS (Climate Hazards Group InfraRed Precipitation with Station data)
Dataset satelital de precipitaciÃ³n a 0.05Â° de resoluciÃ³n, usado para validaciÃ³n cruzada.

**Cobertura:** Global, 1981-presente, actualizaciÃ³n cuasi-tiempo real.

### ClimatologÃ­a
Promedio de largo plazo (tÃ­picamente 30 aÃ±os) de una variable climÃ¡tica para cada dÃ­a/mes del aÃ±o.

**Uso como baseline:** PronÃ³stico = precipitaciÃ³n promedio para esa fecha del aÃ±o.

### ConvoluciÃ³n (Convolutional Layer)
OperaciÃ³n que aplica filtros (kernels) a una ventana espacial de datos para extraer caracterÃ­sticas locales.

**Ejemplo:**
```python
Conv2D(filters=64, kernel_size=3, padding='same')
```

### Conv2DTranspose
OperaciÃ³n de convoluciÃ³n "inversa" usada para upsampling en decoders. Proyecta de baja a alta resoluciÃ³n espacial.

**Ventaja sobre UpSampling2D:** ImplementaciÃ³n determinista compatible con GPUs.

### Covarianza Espacial
Medida de co-variaciÃ³n entre valores de un campo en dos ubicaciones separadas por una distancia h.

**Relacionado:** Variograma, funciÃ³n de covarianza, correlaciÃ³n espacial.

---

## D

### Data Augmentation
TÃ©cnicas para aumentar artificialmente el tamaÃ±o del dataset mediante transformaciones (rotaciones, traslaciones, ruido).

**No usado en el proyecto:** Preservamos estructura espacial real de precipitaciones.

### Dataset
Conjunto de datos usado para entrenamiento, validaciÃ³n y prueba de modelos.

**Splits del proyecto:**
- Train: 70% (251 secuencias)
- Validation: 15% (53 secuencias)
- Test: 15% (55 secuencias)

### Decoder
Componente del autoencoder que reconstruye los datos originales desde la representaciÃ³n latente comprimida.

**Arquitectura:** Conv2DTranspose â†’ BatchNorm â†’ Upsampling (Ã—3 bloques).

### Determinismo
Propiedad de un algoritmo que produce resultados idÃ©nticos con las mismas entradas y configuraciÃ³n.

**ImplementaciÃ³n:**
```python
SEED = 42
tf.random.set_seed(SEED)
os.environ['TF_DETERMINISTIC_OPS'] = '1'
```

### Dilated Convolution (ConvoluciÃ³n Dilatada)
ConvoluciÃ³n con "huecos" entre pÃ­xeles del kernel, permitiendo receptive fields grandes sin aumentar parÃ¡metros.

**Dilations usadas:** [1, 2, 4, 8] para alcanzar RF â‰ˆ 40 celdas.

### DMD (Dynamic Mode Decomposition)
TÃ©cnica de anÃ¡lisis de sistemas dinÃ¡micos que descompone series temporales en modos oscilatorios con frecuencias y tasas de crecimiento/decaimiento.

**AplicaciÃ³n:** ProyecciÃ³n temporal de embeddings latentes del autoencoder.

### Dropout
TÃ©cnica de regularizaciÃ³n que desactiva aleatoriamente un porcentaje de neuronas durante entrenamiento para prevenir overfitting.

**No usado en el proyecto:** Preferimos regularizaciÃ³n L2 por interpretabilidad.

---

## E

### Early Stopping
Estrategia que detiene el entrenamiento cuando la mÃ©trica de validaciÃ³n deja de mejorar por un nÃºmero de Ã©pocas (patience).

**ConfiguraciÃ³n:** Patience = 15 Ã©pocas, restore_best_weights = True.

### ECMWF (European Centre for Medium-Range Weather Forecasts)
Centro europeo que produce reanÃ¡lisis ERA5, considerado gold standard en datos meteorolÃ³gicos.

### EDA (Exploratory Data Analysis)
AnÃ¡lisis exploratorio de datos para entender distribuciones, patrones, anomalÃ­as y relaciones antes del modelado.

**Notebook 01:** EDA espacio-temporal de precipitaciones.

### Embedding (RepresentaciÃ³n Latente)
RepresentaciÃ³n comprimida de alta dimensiÃ³n de datos en un espacio de menor dimensiÃ³n que preserva estructura semÃ¡ntica.

**DimensiÃ³n latente:** 64 valores por snapshot espacial.

### Encoder
Componente del autoencoder que comprime datos de alta dimensiÃ³n a representaciÃ³n latente de baja dimensiÃ³n.

**Arquitectura:** Conv2D dilatadas â†’ MaxPooling (Ã—3) â†’ Flatten â†’ Dense.

### Ã‰poca (Epoch)
Una pasada completa del algoritmo de entrenamiento sobre todo el dataset.

**Entrenamiento:** 100 Ã©pocas (stopped en 97 por early stopping).

### ERA5 (ECMWF Reanalysis v5)
Dataset de reanÃ¡lisis global horario a 0.25Â° de resoluciÃ³n (1940-presente) que combina observaciones con modelos fÃ­sicos.

**Variables usadas:** Total Precipitation (tp) en metros.

### Error CuadrÃ¡tico Medio â†’ Ver **MSE**

### Estacionalidad
PatrÃ³n recurrente en series temporales con periodo anual (4 estaciones).

**En Chile:**
- Norte: MÃ¡ximo verano (lluvias altiplÃ¡nicas)
- Centro: MÃ¡ximo invierno (frentes frÃ­os)
- Sur: Distribuido todo el aÃ±o (ocÃ©ano)

### Evento Extremo
Evento de precipitaciÃ³n que excede un umbral estadÃ­stico (tÃ­picamente percentil 95 o 99).

**DefiniciÃ³n en proyecto:** PrecipitaciÃ³n â‰¥ 10 mm/dÃ­a (6.2% de pÃ­xeles).

---

## F

### Feature Map
Salida de una capa convolucional que representa caracterÃ­sticas aprendidas de los datos de entrada.

**Ejemplo:** Primera capa extrae 32 feature maps de bordes/texturas.

### Forecast Horizon (Horizonte de PronÃ³stico)
Tiempo futuro para el cual se realiza una predicciÃ³n.

**Horizontes evaluados:** 1, 3 y 7 dÃ­as adelante.

### Forecasting
Proceso de predecir valores futuros de una variable basÃ¡ndose en observaciones pasadas.

### FunciÃ³n de Covarianza
FunciÃ³n que describe la covarianza entre dos puntos separados por un vector h.

**RelaciÃ³n con variograma:**
```
C(h) = C(0) - Î³(h)
```

---

## G

### Gaussian (Modelo)
Modelo de variograma con transiciÃ³n suave sin punto de inflexiÃ³n.

**EcuaciÃ³n:**
```
Î³(h) = nugget + sill * [1 - exp(-(h/range)Â²)]
```

### GeoestadÃ­stica
Rama de la estadÃ­stica espacial que estudia variables regionalizadas con correlaciÃ³n espacial, desarrollando mÃ©todos como kriging y variogramas.

**AplicaciÃ³n:** DiseÃ±o de arquitectura CNN y loss function ponderada.

### GPU (Graphics Processing Unit)
Procesador especializado en cÃ¡lculos paralelos, esencial para entrenar redes neuronales profundas.

**GPU usada:** NVIDIA compatible con TensorFlow determinista.

### Gradiente (Gradient)
Vector de derivadas parciales que indica la direcciÃ³n de mÃ¡ximo crecimiento de una funciÃ³n.

**En deep learning:** Usado por backpropagation para actualizar pesos.

### Grid (Grilla Espacial)
DiscretizaciÃ³n regular del espacio en celdas rectangulares.

**Grid ERA5:** 157 latitudes Ã— 41 longitudes (0.25Â° resoluciÃ³n).

### Grid Search
MÃ©todo de optimizaciÃ³n exhaustiva que prueba todas las combinaciones de hiperparÃ¡metros en un grid predefinido.

**Notebook 06:** 13 configuraciones planificadas.

---

## H

### HiperparÃ¡metro
ParÃ¡metro del modelo que se fija antes del entrenamiento (no es aprendido por el algoritmo).

**Ejemplos:** learning_rate, batch_size, latent_dim, epochs.

### Horizonte â†’ Ver **Forecast Horizon**

---

## I

### IsotropÃ­a
Propiedad de un campo espacial donde la correlaciÃ³n depende solo de la distancia (no de la direcciÃ³n).

**AsunciÃ³n en variograma:** Simplifica modelado, aproximaciÃ³n razonable para precipitaciones.

### InterpolaciÃ³n Espacial
Proceso de estimar valores en ubicaciones no observadas basÃ¡ndose en valores cercanos conocidos.

**MÃ©todo usado:** Kriging Ordinario (Ã³ptimo bajo supuestos gaussianos).

---

## K

### Keras
API de alto nivel para construir redes neuronales, integrada en TensorFlow 2.x.

**Ventajas:** Sintaxis simple, callbacks, integraciÃ³n con TensorBoard.

### Kernel (en CNN)
Matriz pequeÃ±a de pesos que se desliza sobre la entrada para realizar convoluciÃ³n y extraer caracterÃ­sticas.

**TamaÃ±os usados:** 3Ã—3 (estÃ¡ndar para capturar patrones locales).

### KoVAE (Kolmogorov-Arnold Variational Autoencoder)
Variante de VAE que usa teorema de Kolmogorov-Arnold para representaciones mÃ¡s interpretables.

**Notebook 05:** ImplementaciÃ³n exploratoria comparativa.

### Kriging
MÃ©todo geoestadÃ­stico de interpolaciÃ³n espacial que minimiza varianza del error de estimaciÃ³n.

**Propiedades:**
- Insesgado: E[Z*(s) - Z(s)] = 0
- Ã“ptimo: Minimiza Var[Z*(s) - Z(s)]
- Provee incertidumbre: Varianza kriging ÏƒÂ²(s)

### Kriging Ordinario
Variante de kriging que asume media desconocida pero constante en el dominio.

**EcuaciÃ³n del predictor:**
```
Z*(sâ‚€) = Î£áµ¢ Î»áµ¢ Z(sáµ¢)
RestricciÃ³n: Î£áµ¢ Î»áµ¢ = 1
```

---

## L

### L2 Regularization (RegularizaciÃ³n L2)
PenalizaciÃ³n aÃ±adida a la funciÃ³n de pÃ©rdida proporcional a la suma de cuadrados de los pesos.

**Objetivo:** Prevenir overfitting favoreciendo pesos pequeÃ±os.

**FÃ³rmula:**
```
Loss_total = Loss_original + Î» * Î£(wÂ²)
```

**Î» usado:** 0.0001

### Lag (en variograma)
Distancia de separaciÃ³n h entre pares de puntos usada para calcular semivarianza.

**20 lags usados:** Desde 0Â° hasta ~10Â° con intervalos regulares.

### Latent Dimension (DimensiÃ³n Latente)
TamaÃ±o del espacio embedding (nÃºmero de variables latentes).

**Valor usado:** 64 (compresiÃ³n 100.3x desde 6437 pÃ­xeles).

### Learning Rate (Tasa de Aprendizaje)
HiperparÃ¡metro que controla el tamaÃ±o del paso en la actualizaciÃ³n de pesos durante entrenamiento.

**Valor inicial:** 0.001 (Adam optimizer)  
**Decay:** ReduceLROnPlateau con factor=0.5, patience=7

### Likelihood (Verosimilitud)
Probabilidad de observar los datos dado un modelo con parÃ¡metros especÃ­ficos.

**En variograma:** MaximizaciÃ³n de verosimilitud para ajustar parÃ¡metros.

### Linear Activation
FunciÃ³n de activaciÃ³n identidad: f(x) = x, usada en capas de salida para regresiÃ³n.

**Capa output:**
```python
layers.Conv2D(1, 3, activation='linear')
```

### Loss Function (FunciÃ³n de PÃ©rdida)
MÃ©trica que cuantifica la discrepancia entre predicciones y valores reales, minimizada durante entrenamiento.

**Loss usado:** Weighted MSE ponderado por varianza kriging.

### LSTM (Long Short-Term Memory)
Arquitectura de red neuronal recurrente que puede capturar dependencias de largo plazo en secuencias.

**No usado en el proyecto:** Preferimos DMD para dinÃ¡mica temporal por interpretabilidad.

---

## M

### Macrozona
DivisiÃ³n geogrÃ¡fica de Chile en regiones climÃ¡ticas homogÃ©neas.

**3 macrozonas:**
- **Norte:** -17Â° a -30Â° (Ã¡rido)
- **Centro:** -30Â° a -40Â° (mediterrÃ¡neo)
- **Sur:** -40Â° a -56Â° (templado oceÃ¡nico)

### MAE (Mean Absolute Error)
Promedio de valores absolutos de errores de predicciÃ³n.

**FÃ³rmula:**
```
MAE = (1/n) * Î£|yáµ¢ - Å·áµ¢|
```

**Ventaja:** Interpretable en unidades originales (mm/dÃ­a).

### MaxPooling
OperaciÃ³n de downsampling que toma el valor mÃ¡ximo en una ventana espacial.

**ConfiguraciÃ³n:** MaxPooling2D(2,2) reduce dimensiones a la mitad.

### Media MÃ³vil (Moving Average)
Promedio de ventana deslizante usado para suavizar series temporales y resaltar tendencias.

**Ventana usada:** 7 dÃ­as para visualizar patrones semanales.

### Modelo EsfÃ©rico (Spherical Model)
Modelo de variograma con crecimiento lineal inicial y plateau en el range.

**EcuaciÃ³n:**
```
Î³(h) = nugget + sill * [1.5(h/r) - 0.5(h/r)Â³]  si h â‰¤ r
Î³(h) = nugget + sill                            si h > r
```

**ParÃ¡metros ajustados:** Range=8.15Â°, Sill=23.67, Nugget=0.0

### MSE (Mean Squared Error)
Promedio de errores al cuadrado, penaliza mÃ¡s los errores grandes que MAE.

**FÃ³rmula:**
```
MSE = (1/n) * Î£(yáµ¢ - Å·áµ¢)Â²
```

### Multi-step Forecasting
PredicciÃ³n de mÃºltiples pasos temporales futuros (horizontes 1, 3, 7 dÃ­as).

**Estrategia:** ProyecciÃ³n DMD con A^h donde h es el horizonte.

---

## N

### NetCDF (Network Common Data Form)
Formato de archivo autodescriptivo para datos cientÃ­ficos multidimensionales (tiempo, lat, lon, variables).

**Archivos usados:**
- `era5_precipitation_chile_full.nc` (45.46 MB)
- `kriging_precipitation_june_2020.nc`

### NormalizaciÃ³n
TransformaciÃ³n de datos a escala estÃ¡ndar (tÃ­picamente media 0, varianza 1) para mejorar convergencia de redes neuronales.

**MÃ©todo usado:** StandardScaler (z-score).

### Nugget Effect
Discontinuidad en el origen del variograma que representa variabilidad a escalas menores que la resoluciÃ³n de muestreo o ruido de mediciÃ³n.

**Valor ajustado:** Nugget = 0.0 â†’ Datos limpios sin ruido sub-grid significativo.

---

## O

### Optimizer (Optimizador)
Algoritmo que actualiza pesos de la red neuronal para minimizar la funciÃ³n de pÃ©rdida.

**Optimizador usado:** Adam (Adaptive Moment Estimation)
- Combina momentum y RMSprop
- Adaptativo por parÃ¡metro
- Robusto a gradientes ruidosos

### Overfitting
FenÃ³meno donde el modelo aprende ruido y detalles especÃ­ficos del training set, perdiendo capacidad de generalizaciÃ³n.

**MitigaciÃ³n:**
- RegularizaciÃ³n L2
- Early stopping
- Datos de validaciÃ³n independientes

---

## P

### Padding
Estrategia para manejar bordes en convoluciones agregando pÃ­xeles extra alrededor de la entrada.

**Tipos:**
- `'same'`: Mantiene dimensiones (usado en el proyecto)
- `'valid'`: Sin padding, reduce dimensiones

### ParÃ¡metros (del modelo)
Pesos y sesgos de la red neuronal que son aprendidos durante el entrenamiento.

**Conteo total:** ~2.5M parÃ¡metros en el autoencoder.

### Patience (en callbacks)
NÃºmero de Ã©pocas sin mejora antes de activar early stopping o reducciÃ³n de learning rate.

**ConfiguraciÃ³n:**
- EarlyStopping: patience=15
- ReduceLROnPlateau: patience=7

### Percentil
Valor bajo el cual cae un porcentaje dado de observaciones.

**P95 (percentil 95):**
- Norte: 2.10 mm/dÃ­a
- Centro: 5.78 mm/dÃ­a
- Sur: 8.82 mm/dÃ­a

### Persistence (Modelo)
Baseline que asume el futuro serÃ¡ igual al Ãºltimo valor observado.

**EcuaciÃ³n:**
```
Å·(t+h) = y(t)  âˆ€h > 0
```

### Pooling â†’ Ver **MaxPooling**

### PrecipitaciÃ³n Total (Total Precipitation)
Suma de precipitaciÃ³n convectiva y estratiforme, variable clave del proyecto.

**Unidades ERA5:** Metros (convertidos a mm/dÃ­a).

---

## R

### RÂ² (Coeficiente de DeterminaciÃ³n)
ProporciÃ³n de varianza en la variable dependiente explicada por el modelo.

**FÃ³rmula:**
```
RÂ² = 1 - SS_res / SS_tot
```

**RÂ² kriging:** 0.9923 (ajuste excelente).

### Range (Rango en variograma)
Distancia a partir de la cual la semivarianza se estabiliza en el sill (correlaciÃ³n espacial se vuelve despreciable).

**Valor ajustado:** 8.15Â° (~905 km)

**InterpretaciÃ³n:** Dos puntos separados >8.15Â° son espacialmente independientes.

### ReanÃ¡lisis (Reanalysis)
Dataset que combina observaciones histÃ³ricas con modelos numÃ©ricos para producir grids consistentes espacio-temporales.

**ERA5:** ReanÃ¡lisis de quinta generaciÃ³n del ECMWF.

### Receptive Field (Campo Receptivo)
RegiÃ³n de la entrada que influye en la activaciÃ³n de una neurona especÃ­fica en capas profundas.

**RF del proyecto:** ~40 celdas (cumple requisito de 33 del variograma).

### ReconstrucciÃ³n (en autoencoder)
Output del decoder que intenta recuperar la entrada original desde la representaciÃ³n latente.

**MÃ©trica:** MAE entre input y reconstrucciÃ³n = 0.348 (escala normalizada).

### ReducciÃ³n de Dimensionalidad
Proceso de proyectar datos de alta dimensiÃ³n a menor dimensiÃ³n preservando informaciÃ³n importante.

**TÃ©cnicas:** PCA (lineal), Autoencoders (no lineal), UMAP.

### RegularizaciÃ³n
TÃ©cnicas para prevenir overfitting penalizando modelos complejos.

**Tipos usados:**
- L2 regularization (Î»=0.0001)
- Early stopping
- Batch normalization

### ReLU (Rectified Linear Unit)
FunciÃ³n de activaciÃ³n no lineal: f(x) = max(0, x).

**Ventajas:** Simple, no saturaciÃ³n para x>0, gradientes no desaparecen.

### Residuo (Residual)
Diferencia entre valor observado y predicho: e = y - Å·.

**AnÃ¡lisis de residuos:** DiagnÃ³stico de sesgo, heteroscedasticidad, autocorrelaciÃ³n.

### ResoluciÃ³n Espacial
TamaÃ±o de la celda de grid, determina el nivel de detalle espacial.

**ERA5:** 0.25Â° (~28 km en latitudes medias)
**CHIRPS:** 0.05Â° (~5.5 km)
**Kriging:** 0.1Â° (~11 km)

### RMSE (Root Mean Squared Error)
RaÃ­z cuadrada del MSE, tiene las mismas unidades que la variable original.

**FÃ³rmula:**
```
RMSE = âˆš[(1/n) * Î£(yáµ¢ - Å·áµ¢)Â²]
```

---

## S

### Scaler â†’ Ver **StandardScaler**

### SEED (Semilla Aleatoria)
Valor inicial que determina la secuencia de nÃºmeros pseudoaleatorios, garantiza reproducibilidad.

**Valor usado:** 42 (convenciÃ³n de la comunidad cientÃ­fica).

### Semivarianza (Semivariance)
Mitad de la varianza promedio de diferencias entre pares de puntos separados por distancia h.

**FÃ³rmula:**
```
Î³(h) = (1/2N(h)) * Î£[Z(sáµ¢) - Z(sáµ¢+h)]Â²
```

### Sequence (Secuencia Temporal)
Ventana deslizante de observaciones consecutivas usada como input del modelo.

**Ventana usada:** 7 dÃ­as (7 snapshots consecutivos).

### Sill
Valor asintÃ³tico del variograma, representa la varianza total del campo.

**Valor ajustado:** 23.67 mmÂ²/dÃ­aÂ²

**InterpretaciÃ³n:** Varianza mÃ¡xima entre puntos no correlacionados.

### Skip Connection
ConexiÃ³n directa que salta capas, permite flujo de gradientes y preserva informaciÃ³n.

**No usado explÃ­citamente:** Arquitectura simple encoder-decoder sin ResNet-style skips.

### Snapshot
Estado completo del campo espacial en un instante de tiempo.

**Ejemplo:** PrecipitaciÃ³n en 6437 pÃ­xeles de Chile en un dÃ­a especÃ­fico.

### Spatial Weights (Pesos Espaciales)
Ponderaciones usadas en loss function derivadas de la inversa de la varianza kriging.

**Racionalidad:** Mayor peso en zonas de baja incertidumbre.

### Split (Train/Val/Test)
DivisiÃ³n del dataset en conjuntos independientes para entrenamiento, validaciÃ³n y prueba.

**Proporciones:** 70% / 15% / 15%

### StandardScaler
Normalizador que transforma datos a media 0 y desviaciÃ³n estÃ¡ndar 1.

**TransformaciÃ³n:**
```
z = (x - Î¼) / Ïƒ
```

### Stride
Paso del desplazamiento del kernel en convoluciones o pooling.

**Stride=2:** Reduce dimensiones a la mitad (downsampling).

### SVD (Singular Value Decomposition)
FactorizaciÃ³n matricial: A = UÎ£Váµ€, usada en DMD para identificar modos dinÃ¡micos.

**SVD rank:** NÃºmero de valores singulares retenidos (0.99 = 99% varianza).

---

## T

### TensorFlow
Framework de cÃ³digo abierto de Google para machine learning y redes neuronales.

**VersiÃ³n usada:** 2.10.0 (compatible con determinismo GPU).

### TopografÃ­a
Relieve del terreno que influye fuertemente en precipitaciones por forzamiento orogrÃ¡fico.

**Cordillera de los Andes:** Barrera que crea gradiente de precipitaciÃ³n este-oeste.

### Training Loop
Proceso iterativo de forward pass (predicciÃ³n) + backward pass (gradientes) + actualizaciÃ³n de pesos.

### Transpose Convolution â†’ Ver **Conv2DTranspose**

---

## U

### Upsampling
Proceso de aumentar la resoluciÃ³n espacial de un tensor.

**MÃ©todos:**
- `UpSampling2D`: Duplica pÃ­xeles (no determinista en GPU)
- `Conv2DTranspose`: ConvoluciÃ³n inversa (determinista, usado en proyecto)

---

## V

### ValidaciÃ³n Cruzada (Cross-Validation)
TÃ©cnica que evalÃºa modelos en mÃºltiples particiones del dataset para estimar performance generalizada.

**ValidaciÃ³n del proyecto:** Split simple (70/15/15) en lugar de k-fold por limitaciÃ³n temporal de datos.

### Variable Regionalizada
Variable distribuida en el espacio con estructura de correlaciÃ³n espacial.

**Ejemplo:** Campo de precipitaciÃ³n Z(s) donde s es ubicaciÃ³n geogrÃ¡fica.

### Varianza
Medida de dispersiÃ³n: promedio de desviaciones al cuadrado respecto a la media.

**Varianza ERA5 (pre-normalizaciÃ³n):** 34.40 mmÂ²/dÃ­aÂ²

### Variograma
FunciÃ³n que describe cÃ³mo la varianza entre pares de puntos aumenta con la distancia.

**Modelo ajustado:** EsfÃ©rico con range=8.15Â°, sill=23.67, nugget=0.

**Aplicaciones:**
1. DiseÃ±o de receptive field CNN
2. Kriging para interpolaciÃ³n
3. Pesos espaciales en loss function

### Variograma Experimental
EstimaciÃ³n empÃ­rica del variograma a partir de datos observados antes de ajustar modelo teÃ³rico.

**CÃ¡lculo:**
```
Î³Ì‚(h) = (1/2|N(h)|) * Î£[Z(sáµ¢) - Z(sâ±¼)]Â²
```

### Variograma TeÃ³rico
Modelo paramÃ©trico (esfÃ©rico, exponencial, gaussiano) ajustado al variograma experimental.

**Ventaja:** Suaviza ruido, permite interpolaciÃ³n, garantiza propiedades matemÃ¡ticas.

---

## W

### Weight Decay â†’ Ver **L2 Regularization**

### Weighted Loss
FunciÃ³n de pÃ©rdida donde diferentes muestras o pÃ­xeles tienen ponderaciones distintas.

**ImplementaciÃ³n:**
```python
weighted_error = squared_error * spatial_weights
```

### Window Size
TamaÃ±o de la ventana temporal de observaciones pasadas usadas para predicciÃ³n.

**Valor usado:** 7 dÃ­as (una semana).

---

## ğŸ“Š SIGLAS Y ACRÃ“NIMOS

| Sigla | Significado | Contexto |
|-------|-------------|----------|
| **AE** | Autoencoder | Arquitectura de red neuronal |
| **API** | Application Programming Interface | Interfaz de programaciÃ³n |
| **BN** | Batch Normalization | TÃ©cnica de normalizaciÃ³n |
| **CHIRPS** | Climate Hazards Infrared Precipitation with Stations | Dataset satelital |
| **CNN** | Convolutional Neural Network | Red neuronal convolucional |
| **CSV** | Comma-Separated Values | Formato de archivo |
| **DL** | Deep Learning | Aprendizaje profundo |
| **DMD** | Dynamic Mode Decomposition | DescomposiciÃ³n de modos dinÃ¡micos |
| **DRY** | Don't Repeat Yourself | Principio de programaciÃ³n |
| **ECMWF** | European Centre for Medium-Range Weather Forecasts | Centro meteorolÃ³gico europeo |
| **EDA** | Exploratory Data Analysis | AnÃ¡lisis exploratorio |
| **ERA5** | ECMWF Reanalysis v5 | Dataset de reanÃ¡lisis |
| **GFS** | Global Forecast System | Sistema de pronÃ³stico NOAA |
| **GPU** | Graphics Processing Unit | Procesador grÃ¡fico |
| **KoVAE** | Kolmogorov-Arnold Variational Autoencoder | Variante de autoencoder |
| **LSTM** | Long Short-Term Memory | Arquitectura de RNN |
| **MAE** | Mean Absolute Error | Error absoluto medio |
| **MCP** | Model Context Protocol | Protocolo de contexto |
| **MSE** | Mean Squared Error | Error cuadrÃ¡tico medio |
| **NetCDF** | Network Common Data Form | Formato de datos cientÃ­ficos |
| **OK** | Ordinary Kriging | Kriging ordinario |
| **PCA** | Principal Component Analysis | AnÃ¡lisis de componentes principales |
| **PDO** | Pacific Decadal Oscillation | OscilaciÃ³n decenal del PacÃ­fico |
| **ReLU** | Rectified Linear Unit | Unidad lineal rectificada |
| **RF** | Receptive Field | Campo receptivo |
| **RMSE** | Root Mean Squared Error | RaÃ­z del error cuadrÃ¡tico medio |
| **RNN** | Recurrent Neural Network | Red neuronal recurrente |
| **SAM** | Southern Annular Mode | Modo anular del sur |
| **SEED** | Semilla | Valor inicial aleatorio |
| **SVD** | Singular Value Decomposition | DescomposiciÃ³n en valores singulares |
| **TF** | TensorFlow | Framework de deep learning |
| **UDD** | Universidad del Desarrollo | InstituciÃ³n acadÃ©mica |
| **UMAP** | Uniform Manifold Approximation and Projection | TÃ©cnica de reducciÃ³n dimensional |
| **VAE** | Variational Autoencoder | Autoencoder variacional |
| **WRF** | Weather Research and Forecasting | Modelo meteorolÃ³gico |

---

## ğŸ§® FÃ“RMULAS PRINCIPALES

### 1. Variograma EsfÃ©rico
```
Î³(h) = {
    nugget + sill * [1.5(h/range) - 0.5(h/range)Â³]  si h â‰¤ range
    nugget + sill                                    si h > range
}
```

**ParÃ¡metros del proyecto:**
- nugget = 0.0
- sill = 23.67 mmÂ²/dÃ­aÂ²
- range = 8.15Â° â‰ˆ 905 km

---

### 2. Kriging Ordinario

**Sistema de ecuaciones:**
```
â”Œ                    â”   â”Œ    â”   â”Œ       â”
â”‚ Î³(sâ‚,sâ‚) ... Î³(sâ‚,sâ‚™) â”‚ â”‚ 1 â”‚   â”‚ Î»â‚    â”‚   â”‚ Î³(sâ‚€,sâ‚) â”‚
â”‚    â‹®      â‹±      â‹®    â”‚ â”‚ â‹® â”‚ Ã— â”‚  â‹®    â”‚ = â”‚    â‹®     â”‚
â”‚ Î³(sâ‚™,sâ‚) ... Î³(sâ‚™,sâ‚™) â”‚ â”‚ 1 â”‚   â”‚ Î»â‚™    â”‚   â”‚ Î³(sâ‚€,sâ‚™) â”‚
â”‚    1     ...    1     â”‚ â”‚ 0 â”‚   â”‚ Î¼     â”‚   â”‚    1     â”‚
â””                    â”˜   â””    â”˜   â””       â”˜   â””         â”˜
```

**Predictor:**
```
Z*(sâ‚€) = Î£áµ¢â‚Œâ‚â¿ Î»áµ¢ Z(sáµ¢)
```

**Varianza kriging:**
```
ÏƒÂ²â‚–(sâ‚€) = Î£áµ¢â‚Œâ‚â¿ Î»áµ¢ Î³(sâ‚€,sáµ¢) + Î¼
```

---

### 3. Weighted MSE Loss
```
L_weighted = (1/N) Î£áµ¢â‚Œâ‚á´º wáµ¢ * (yáµ¢ - Å·áµ¢)Â²

donde wáµ¢ = 1 / (ÏƒÂ²â‚–(sáµ¢) + Îµ)
```

**Îµ:** PequeÃ±a constante para estabilidad numÃ©rica.

---

### 4. Batch Normalization
```
BN(x) = Î³ * ((x - Î¼_batch) / âˆš(ÏƒÂ²_batch + Îµ)) + Î²

Î¼_batch = (1/m) Î£áµ¢â‚Œâ‚áµ xáµ¢
ÏƒÂ²_batch = (1/m) Î£áµ¢â‚Œâ‚áµ (xáµ¢ - Î¼_batch)Â²
```

**Î³, Î²:** ParÃ¡metros aprendibles.

---

### 5. Receptive Field (CNN)
Para convoluciones de tamaÃ±o k con dilation d:
```
RF_out = RF_in + (k-1) * d
```

**Ejemplo (dilation=[1,2,4,8], k=3):**
```
Capa 1: RF = 1 + 2*1 = 3
Capa 2: RF = 3 + 2*2 = 7
Capa 3: RF = 7 + 2*4 = 15
Capa 4: RF = 15 + 2*8 = 31
+ pooling: RF â‰ˆ 40 celdas
```

---

### 6. MÃ©tricas de EvaluaciÃ³n

**MAE (Mean Absolute Error):**
```
MAE = (1/n) Î£áµ¢â‚Œâ‚â¿ |yáµ¢ - Å·áµ¢|
```

**RMSE (Root Mean Squared Error):**
```
RMSE = âˆš[(1/n) Î£áµ¢â‚Œâ‚â¿ (yáµ¢ - Å·áµ¢)Â²]
```

**RÂ² (Coeficiente de DeterminaciÃ³n):**
```
RÂ² = 1 - (SS_res / SS_tot)

SS_res = Î£áµ¢ (yáµ¢ - Å·áµ¢)Â²
SS_tot = Î£áµ¢ (yáµ¢ - È³)Â²
```

---

### 7. StandardScaler (NormalizaciÃ³n)
```
TransformaciÃ³n: z = (x - Î¼) / Ïƒ

Î¼ = (1/n) Î£áµ¢â‚Œâ‚â¿ xáµ¢
Ïƒ = âˆš[(1/n) Î£áµ¢â‚Œâ‚â¿ (xáµ¢ - Î¼)Â²]

Inversa: x = z * Ïƒ + Î¼
```

---

### 8. DMD (Dynamic Mode Decomposition)

**DescomposiciÃ³n SVD:**
```
X = U Î£ Váµ€
```

**Matriz de transiciÃ³n:**
```
A = X' V Î£â»Â¹ Uáµ€
```

**Eigenvalues y modos:**
```
A Î¦ = Î¦ Î›
```

**ProyecciÃ³n temporal:**
```
x(t+h) = AÊ° x(t)
```

---

## ğŸ“– REFERENCIAS BIBLIOGRÃFICAS

### GeoestadÃ­stica
1. **Cressie, N. (1993).** Statistics for Spatial Data. Wiley.
2. **ChilÃ¨s, J.-P., & Delfiner, P. (2012).** Geostatistics: Modeling Spatial Uncertainty. Wiley.
3. **Webster, R., & Oliver, M. A. (2007).** Geostatistics for Environmental Scientists. Wiley.

### Deep Learning
4. **Goodfellow, I., Bengio, Y., & Courville, A. (2016).** Deep Learning. MIT Press.
5. **Chollet, F. (2021).** Deep Learning with Python. Manning.

### DMD y Sistemas DinÃ¡micos
6. **Kutz, J. N., Brunton, S. L., Brunton, B. W., & Proctor, J. L. (2016).** Dynamic Mode Decomposition. SIAM.
7. **Schmid, P. J. (2010).** Dynamic mode decomposition of numerical and experimental data. Journal of Fluid Mechanics.

### MeteorologÃ­a y ClimatologÃ­a
8. **Hersbach, H., et al. (2020).** The ERA5 global reanalysis. Quarterly Journal of the Royal Meteorological Society.
9. **Funk, C., et al. (2015).** The climate hazards infrared precipitation with stations (CHIRPS) dataset. Scientific Data.

---

## ğŸ“ NOTAS DE USO

### Convenciones en el Glosario

- **Negrita:** TÃ©rmino definido
- *Cursiva:* Ã‰nfasis o tÃ©rmino tÃ©cnico
- `CÃ³digo`: Sintaxis de programaciÃ³n
- **â†’ Ver:** Referencia cruzada

### Sugerencias de Lectura

**Para principiantes:**
- Leer en orden: A â†’ V â†’ K â†’ M â†’ L
- Enfocarse en conceptos fundamentales antes de tÃ©cnicas avanzadas

**Para usuarios avanzados:**
- Buscar tÃ©rminos especÃ­ficos en el Ã­ndice alfabÃ©tico
- Revisar fÃ³rmulas matemÃ¡ticas para implementaciÃ³n

**Para revisores del proyecto:**
- SecciÃ³n "Siglas y AcrÃ³nimos" para decodificar documentaciÃ³n
- SecciÃ³n "FÃ³rmulas Principales" para validaciÃ³n matemÃ¡tica

---

## ğŸ”„ CONTROL DE VERSIONES

| VersiÃ³n | Fecha | Cambios |
|---------|-------|---------|
| 1.0 | 23-Nov-2025 | VersiÃ³n inicial completa |

---

**Autor:** CÃ©sar Godoy Delaigue  
**Proyecto:** PronÃ³stico HÃ­brido Espacio-Temporal de Precipitaciones en Chile  
**InstituciÃ³n:** Universidad del Desarrollo (UDD)  
**Contacto:** [tu_email@udd.cl]

---

_Este glosario es un documento vivo que se actualizarÃ¡ conforme avance el proyecto._
